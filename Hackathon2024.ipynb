{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde46cc1-1c38-4383-a923-88d397e3dc20",
   "metadata": {},
   "source": [
    "Firstly, let's set up the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17e5e1da-cb4f-4742-9658-76c842c7491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        TweetContent Label\n",
      "0  It's inspiring to see Rome harnessing AI for a...  safe\n",
      "1  ðŸ‘¹ AIRDROP second release more 10 000 GOBLINS ðŸ‘¹...  scam\n",
      "2  I'm happy to see everyone enjoying @HeadsUp. W...  safe\n",
      "3  Highest score I've seen! RT @Nessa Oh yeah! Fi...  safe\n",
      "4  @Jake_Fitch What was your score? RT @trilog3te...  safe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"tweetData.csv\")\n",
    "\n",
    "# Preview data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175b452-220f-4745-9009-15d4f6da98d6",
   "metadata": {},
   "source": [
    "We will now prepare the data for fine-tuning using OpenAI's GPT-4 model.\n",
    "\n",
    "The fine-tuning will take the tweet content into account in order to classify a tweet as one of three types:\n",
    "  - Likely safe\n",
    "  - Likely scam\n",
    "  - Likely fake news (with given source!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8f9c6da-f00d-4727-9970-9d6919c83402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to create a JSONL entry\n",
    "def create_jsonl_entry(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies tweets as either safe, scam, or fake-news.\"},\n",
    "            {\"role\": \"user\", \"content\": \"This tweet says: \" + str(row['TweetContent']) + \"\\nClassify it as:\"},\n",
    "            {\"role\": \"assistant\", \"content\": row['Label']}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Apply the function to each row and write to a JSONL file\n",
    "with open(\"fine_tune_data.jsonl\", \"w\") as f:\n",
    "    for _, row in data.iterrows():\n",
    "        jsonl_entry = create_jsonl_entry(row)\n",
    "        f.write(json.dumps(jsonl_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7a7c63a-63fc-4d2f-802a-acafe1846063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "openai = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "184c671e-995b-4742-82a0-8f6926f59808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-9IsFJeEYeqXAvGeEPIAfH293', bytes=58529, created_at=1730523419, filename='fine_tune_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "file = openai.files.create(file=open(\"fine_tune_data.jsonl\", \"rb\"), purpose='fine-tune')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ca0249d-2c62-4441-815e-2472ddc953eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-3hFpdnW1QH1MdprKHRPr1OBT', created_at=1730523427, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-qbB7poxzsbQf8xgCn62RqYk5', result_files=[], seed=1879177518, status='validating_files', trained_tokens=None, training_file='file-9IsFJeEYeqXAvGeEPIAfH293', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "fine_tune = openai.fine_tuning.jobs.create(training_file='file-9IsFJeEYeqXAvGeEPIAfH293', model=\"gpt-4o-2024-08-06\")\n",
    "print(fine_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5852a8c-520e-41e6-b198-d74027604c29",
   "metadata": {},
   "source": [
    "And let us test the model with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bfdfff00-0b0c-49f4-9f92-aebd57eeb2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-2024-08-06:personal::AP0mZFnN\",  # Replace with your fine-tuned model ID\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies tweets as either safe, scam, or fake-news.\"},\n",
    "        {\"role\": \"user\", \"content\": \"This tweet says: 'What a world we built together!\\n\\nWhat is your favorite zone in all of Azeroth?'\\nClassify it as:\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "#classification = response.choices[0]['message']['content'].strip()\n",
    "#print(\"Classification:\", classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
