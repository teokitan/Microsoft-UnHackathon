{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73446878-e52f-4cfd-a684-e0f1dd8cbdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FileName Label                                      Transcription\n",
      "0  file1-Fake.mp4  fake  news Disneyworld officially removed the drinki...\n",
      "1  file2-Fake.mp4  fake  information it's game on for everyone at first...\n",
      "2  file3-Fake.mp4  fake  how bad is 5G for your health while you're her...\n",
      "3  file4-Fake.mp4  fake  so 5G technology if you notice before they put...\n",
      "4  file5-Fake.mp4  fake  so if you think this is going to be no big dea...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"NewTikTokData.csv\")\n",
    "\n",
    "# Preview data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd880a37-72e3-4b32-853d-663179152349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to create a JSONL entry\n",
    "def create_jsonl_entry(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies transcripts of TikTok videos as 'fake' (if it contains fake information), 'real' (if it contains some information but is likely true), or 'safe' (if it contains no claims).\"},\n",
    "            {\"role\": \"user\", \"content\": \"This TikTok says: \" + str(row['Transcription']) + \"\\nClassify it as:\"},\n",
    "            {\"role\": \"assistant\", \"content\": row['Label']}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Apply the function to each row and write to a JSONL file\n",
    "with open(\"fine_tune_data_TIKTOK.jsonl\", \"w\") as f:\n",
    "    for _, row in data.iterrows():\n",
    "        jsonl_entry = create_jsonl_entry(row)\n",
    "        f.write(json.dumps(jsonl_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1e3312-ec92-4c5f-be8d-3c31898aed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "openai = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84cf1b03-8001-4e07-bd12-ce70a4e1993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-ElZ0TjuT0iCwMZUkCmOpHC3z', bytes=17099, created_at=1730562383, filename='fine_tune_data_TIKTOK.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "file = openai.files.create(file=open(\"fine_tune_data_TIKTOK.jsonl\", \"rb\"), purpose='fine-tune')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e848ee3-252e-47d1-9485-7c30b9015ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-vxeAE1VkAieKxwTn2QVhKbMX', created_at=1730562391, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-qbB7poxzsbQf8xgCn62RqYk5', result_files=[], seed=1297693166, status='validating_files', trained_tokens=None, training_file='file-ElZ0TjuT0iCwMZUkCmOpHC3z', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "fine_tune = openai.fine_tuning.jobs.create(training_file='file-ElZ0TjuT0iCwMZUkCmOpHC3z', model=\"gpt-4o-mini-2024-07-18\")\n",
    "print(fine_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d7718f-ebe7-4d64-a26d-38c360afb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/teo/Downloads/psyched-freedom-182221-658209fdfd55.json\"\n",
    "\n",
    "import time\n",
    "from google.cloud import videointelligence_v1 as videointelligence\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_video(file_path):\n",
    "    # Initialize the Video Intelligence API client\n",
    "    client = videointelligence.VideoIntelligenceServiceClient()\n",
    "\n",
    "    # Read the file and load it into the API\n",
    "    with open(file_path, \"rb\") as video_file:\n",
    "        input_content = video_file.read()\n",
    "\n",
    "    # Configure the request for speech transcription\n",
    "    features = [videointelligence.Feature.SPEECH_TRANSCRIPTION]\n",
    "    config = videointelligence.SpeechTranscriptionConfig(\n",
    "        language_code=\"en-US\"  # Adjust language if needed\n",
    "    )\n",
    "    video_context = videointelligence.VideoContext(speech_transcription_config=config)\n",
    "\n",
    "    # Start the operation\n",
    "    operation = client.annotate_video(\n",
    "        request={\"features\": features, \"input_content\": input_content, \"video_context\": video_context}\n",
    "    )\n",
    "\n",
    "    print(f\"Started transcription for {file_path}... Waiting for completion.\")\n",
    "\n",
    "    # Poll the operation status until it completes\n",
    "    while not operation.done():\n",
    "        print(\"Waiting for transcription to finish...\")\n",
    "        time.sleep(10)  # Wait 10 seconds between checks\n",
    "\n",
    "    # Process results after the operation is done\n",
    "    if operation.result():\n",
    "        result = operation.result()\n",
    "        transcription_text = \"\"\n",
    "        for annotation in result.annotation_results[0].speech_transcriptions:\n",
    "            for alternative in annotation.alternatives:\n",
    "                transcription_text += alternative.transcript + \" \"\n",
    "        return transcription_text.strip()\n",
    "    else:\n",
    "        print(f\"Transcription failed for {file_path}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e58023b-c69a-46ae-a99a-d568da2a4bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started transcription for file12-Real.mp4... Waiting for completion.\n",
      "Waiting for transcription to finish...\n",
      "Waiting for transcription to finish...\n",
      "Waiting for transcription to finish...\n",
      "real\n"
     ]
    }
   ],
   "source": [
    "testTranscript = transcribe_video(\"file12-Real.mp4\")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-mini-2024-07-18:personal::APAiF7vv\",  # Replace with your fine-tuned model ID\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies transcripts of TikTok videos as 'fake' (if it contains fake information), 'real' (if it contains some information but is likely true), or 'safe' (if it contains no claims).\"},\n",
    "        {\"role\": \"user\", \"content\": \"This TikTok says: \" + str(testTranscript) + \"\\nClassify it as:\"},\n",
    "        {\"role\": \"assistant\", \"content\": row['Label']}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "classification = response.choices[0].message.content.strip()\n",
    "\n",
    "#classification = response.choices[0]['message']['content'].strip()\n",
    "#print(\"Classification:\", classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8f7bc09-241c-4856-b7ee-272f9070aaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of Questionable Claims:**\n",
      "\n",
      "1. **Jumping before Impact**: The claim states that jumping just before the elevator hits the ground will not save your life and could lead to severe injuries instead. This emphasizes the difficulty of timing the jump correctly when the elevator is already falling quickly.\n",
      "\n",
      "2. **Best Positioning for Survival**: It suggests that lying flat on the floor and protecting your head with hands or a bag will increase your chances of surviving the fall, as it helps distribute impact forces.\n",
      "\n",
      "---\n",
      "\n",
      "**Sources for Verification:**\n",
      "\n",
      "1. **Jumping in a Falling Elevator**:\n",
      "   - *NPR* discusses the fallacy of the jump:\n",
      "     [Why You Can't Jump to Safety in a Falling Elevator](https://www.npr.org/sections/money/2020/12/30/951088836/why-you-cant-jump-to-safety-in-a-falling-elevator)\n",
      "\n",
      "2. **Survival Position in a Falling Elevator**:\n",
      "   - *HowStuffWorks* elaborates on the best positions in case of an elevator fall:\n",
      "     [What Should You Do If an Elevator is Falling?](https://science.howstuffworks.com/science-vs-myth/what-if-elevator-falls.htm)\n",
      "\n",
      "3. **General Safety and Elevator Mechanics**:\n",
      "   - *USA Today* covers elevator safety features and what to do in emergencies:\n",
      "     [What to do in an elevator emergency](https://www.usatoday.com/story/news/nation/2021/09/10/elevator-safety-what-to-do-emergency-fall/5795225001/)\n",
      "\n",
      "---\n",
      "\n",
      "**Overall Opinion:**\n",
      "\n",
      "Based on the information provided in the TikTok and the sources researched, the claims made in the video appear to be real. It is widely accepted by experts that attempting to jump in a falling elevator is not advisable and that lying flat can help minimize injuries. Therefore, the advice given in the video is backed by credible sources.\n"
     ]
    }
   ],
   "source": [
    "if classification == \"fake\" or classification == \"real\":\n",
    "    response2 = openai.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-mini-2024-07-18:personal::APAiF7vv\",  # Replace with your fine-tuned model ID\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You think a TikTok video (for which I'll give you a transcript) likely contains some questionable claims (which may be true or false!). Give me a summary on what the claims exactly are and give me sources to support whether you think they're true or false! Sources need to be real, clickable links that you have researched. They need to be relevant and trustworthy (authoritive).\"},\n",
    "            {\"role\": \"user\", \"content\": \"This TikTok says: \" + str(testTranscript) + \"\\nI think it's \" + classification + \". Give me a summary on questionable claims and sources where I can verify them. Also give me your overall opinion: is it fake or real?\"},\n",
    "            {\"role\": \"assistant\", \"content\": row['Label']}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(response2.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
